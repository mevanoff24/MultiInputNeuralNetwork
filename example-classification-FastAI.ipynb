{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example classification with MixedInputModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from model import *\n",
    "\n",
    "# saved bulldozers data from the first lessons\n",
    "dep = 'SalePrice'\n",
    "PATH = \"data/bulldozers/\"\n",
    "df_raw = pd.read_feather('tmp/bulldozers-raw')\n",
    "keep_cols = list(np.load('tmp/keep_cols.npy'))\n",
    "\n",
    "df_raw.loc[df_raw.YearMade<1950, 'YearMade'] = 1950\n",
    "df_raw['age'] = df_raw.saleYear-df_raw.YearMade\n",
    "df_raw = df_raw[keep_cols+['age', dep]].copy()\n",
    "df_indep = df_raw.drop(dep,axis=1)\n",
    "\n",
    "n_valid = 12000\n",
    "n_trn = len(df_raw)-n_valid\n",
    "\n",
    "\n",
    "cat_flds = [n for n in df_indep.columns if df_raw[n].nunique()<n_trn/50]\n",
    "' '.join(cat_flds)\n",
    "\n",
    "for o in ['saleElapsed', 'saleDayofyear', 'saleDay', 'age', 'YearMade']: cat_flds.remove(o)\n",
    "[n for n in df_indep.drop(cat_flds,axis=1).columns if not is_numeric_dtype(df_raw[n])]\n",
    "\n",
    "\n",
    "for n in cat_flds: df_raw[n] = df_raw[n].astype('category').cat.as_ordered()\n",
    "\n",
    "cont_flds = [n for n in df_indep.columns if n not in cat_flds]\n",
    "\n",
    "df_raw = df_raw[cat_flds+cont_flds+[dep]]\n",
    "df, y, nas, mapper = preprocessing(df_raw, 'SalePrice', do_scale=True)\n",
    "\n",
    "val_idx = list(range(n_trn, len(df)))\n",
    "\n",
    "emb_c = {n: len(c.cat.categories)+1 for n,c in df_raw[cat_flds].items()}\n",
    "\n",
    "emb_szs = [(c, min(50, (c+1)//2)) for _,c in emb_c.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 2 ... 2 2 1]\n"
     ]
    }
   ],
   "source": [
    "# turn `SalePrice` into a categorical variable for a classification problem \n",
    "categorical_y = []\n",
    "for i in y:\n",
    "    if i < 9.0:\n",
    "        categorical_y.append('low')\n",
    "    elif i > 11.0:\n",
    "        categorical_y.append('high')\n",
    "    else:\n",
    "        categorical_y.append('mid')\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "categorical_y = le.fit_transform(categorical_y)\n",
    "categorical_y = np.asarray(categorical_y)\n",
    "print(categorical_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.column_data import ColumnarModelData, StructuredModel\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from fastai.learner import *\n",
    "import torch.nn.functional as F\n",
    "\n",
    "PATH = 'data/'\n",
    "md = ColumnarModelData.from_data_frame(PATH, val_idx, df, categorical_y, cat_flds=cat_flds, bs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create own MixedInputModel class and StructuredLearner class \n",
    "\n",
    "def emb_init(x):\n",
    "    x = x.weight.data\n",
    "    sc = 2/(x.size(1)+1)\n",
    "    x.uniform_(-sc,sc)\n",
    "\n",
    "    \n",
    "class MixedInputModelClassificaiton(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n",
    "                 y_range=None, use_bn=False):\n",
    "        super().__init__()\n",
    "        self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])\n",
    "        for emb in self.embs: emb_init(emb)\n",
    "        n_emb = sum(e.embedding_dim for e in self.embs)\n",
    "        self.n_emb, self.n_cont=n_emb, n_cont\n",
    "        \n",
    "        szs = [n_emb+n_cont] + szs\n",
    "        self.lins = nn.ModuleList([\n",
    "            nn.Linear(szs[i], szs[i+1]) for i in range(len(szs)-1)])\n",
    "        self.bns = nn.ModuleList([\n",
    "            nn.BatchNorm1d(sz) for sz in szs[1:]])\n",
    "        for o in self.lins: kaiming_normal(o.weight.data)\n",
    "        self.outp = nn.Linear(szs[-1], out_sz)\n",
    "        kaiming_normal(self.outp.weight.data)\n",
    "\n",
    "        self.emb_drop = nn.Dropout(emb_drop)\n",
    "        self.drops = nn.ModuleList([nn.Dropout(drop) for drop in drops])\n",
    "        self.bn = nn.BatchNorm1d(n_cont)\n",
    "        self.use_bn,self.y_range = use_bn,y_range\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        if self.n_emb != 0:\n",
    "            x = [e(x_cat[:,i]) for i,e in enumerate(self.embs)]\n",
    "            x = torch.cat(x, 1)\n",
    "            x = self.emb_drop(x)\n",
    "        if self.n_cont != 0:\n",
    "            x2 = self.bn(x_cont)\n",
    "            x = torch.cat([x, x2], 1) if self.n_emb != 0 else x2\n",
    "        for l,d,b in zip(self.lins, self.drops, self.bns):\n",
    "            x = F.relu(l(x))\n",
    "            if self.use_bn: x = b(x)\n",
    "            x = d(x)\n",
    "        x = self.outp(x)\n",
    "        # change to softmax output\n",
    "        x = F.log_softmax(x, dim=-1)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class StructuredLearner(Learner):\n",
    "    def __init__(self, data, models, **kwargs):\n",
    "        super().__init__(data, models, **kwargs)\n",
    "        # change to a classification loss function, \n",
    "        # might not need this if you define your own training loop\n",
    "        self.crit = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to total number of classes \n",
    "num_classes = len(set(categorical_y))\n",
    "model = MixedInputModelClassificaiton(emb_szs, len(cont_flds), 0.04, num_classes, [1000,500], [0.001,0.01])\n",
    "m = StructuredLearner(md, StructuredModel(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred log probs: [-1.04458 -1.10577 -1.14822] -- True: 2\n",
      "pred log probs: [-0.98385 -1.07938 -1.25063] -- True: 2\n",
      "pred log probs: [-1.00442 -1.16467 -1.13408] -- True: 2\n",
      "pred log probs: [-1.12615 -1.03527 -1.13759] -- True: 2\n",
      "pred log probs: [-0.9649  -1.12864 -1.21906] -- True: 2\n",
      "pred log probs: [-1.20009 -1.03089 -1.07253] -- True: 2\n",
      "pred log probs: [-1.01543 -1.14942 -1.13652] -- True: 2\n",
      "pred log probs: [-1.03087 -1.1107  -1.15845] -- True: 0\n",
      "pred log probs: [-1.06692 -1.13093 -1.09901] -- True: 2\n",
      "pred log probs: [-1.16797 -1.10318 -1.02949] -- True: 0\n",
      "pred log probs: [-1.0332  -1.08289 -1.18574] -- True: 0\n",
      "pred log probs: [-1.06535 -0.98435 -1.26688] -- True: 2\n",
      "pred log probs: [-1.26336 -1.03621 -1.01472] -- True: 2\n",
      "pred log probs: [-1.06225 -1.01288 -1.23391] -- True: 2\n",
      "pred log probs: [-1.14893 -1.03823 -1.11187] -- True: 0\n",
      "pred log probs: [-1.25545 -1.02609 -1.03101] -- True: 2\n",
      "pred log probs: [-1.05491 -1.0416  -1.20769] -- True: 1\n",
      "pred log probs: [-1.13548 -1.05051 -1.11178] -- True: 2\n",
      "pred log probs: [-1.06801 -1.08181 -1.14783] -- True: 2\n",
      "pred log probs: [-1.04401 -1.038   -1.22487] -- True: 2\n",
      "pred log probs: [-1.02469 -1.11777 -1.15809] -- True: 2\n",
      "pred log probs: [-1.15332 -1.1201  -1.02676] -- True: 2\n",
      "pred log probs: [-1.1253  -1.24561 -0.94758] -- True: 2\n",
      "pred log probs: [-1.10389 -1.0682  -1.12455] -- True: 2\n",
      "pred log probs: [-1.12201 -1.16593 -1.01406] -- True: 2\n",
      "pred log probs: [-1.045   -1.02902 -1.2346 ] -- True: 2\n",
      "pred log probs: [-1.26712 -1.00794 -1.04019] -- True: 2\n",
      "pred log probs: [-1.0724  -1.01399 -1.22062] -- True: 2\n",
      "pred log probs: [-1.14741 -1.03397 -1.11795] -- True: 0\n",
      "pred log probs: [-0.95862 -1.18278 -1.17069] -- True: 2\n",
      "pred log probs: [-1.11678 -1.06196 -1.11813] -- True: 2\n",
      "pred log probs: [-1.10281 -1.08947 -1.10362] -- True: 2\n"
     ]
    }
   ],
   "source": [
    "# pass in your categorical features, and continious features into your model()\n",
    "# example \n",
    "cat, cont, y = next(iter(md.trn_dl))\n",
    "cat, cont, y = Variable(cat), Variable(cont), Variable(y).long()\n",
    "pred = model(cat, cont)\n",
    "for p, true in zip(pred.data.numpy(), torch.max(y, 1)[0].data):\n",
    "    print('pred log probs: {} -- True: {}'.format(p, true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
